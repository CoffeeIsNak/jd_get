import requests, os, time

def jp_crawler(jp_headers):
    API_URL = "https://www.jobplanet.co.kr/api/v3/search/postings"
    JP_HEADERS = jp_headers
    PARAMS = {
        "occupation_level2": "11913,11916",  # ë°ì´í„° ì—”ì§€ë‹ˆì–´ ê´€ë ¨ ì§êµ° ì½”ë“œ
        "years_of_experience": "0,3",  # 0~2ë…„ ê²½ë ¥
        "order_by": "ranking",
        "query": "",
        "page": 1,  # ì‹œì‘ í˜ì´ì§€
        "page_size": 8  # í•œ ë²ˆì— ê°€ì ¸ì˜¬ ê°œìˆ˜
    }
    all_jobs = []  # ëª¨ë“  ì±„ìš© ê³µê³  ì €ì¥ ë¦¬ìŠ¤íŠ¸
    page = 1  # ì´ˆê¸° í˜ì´ì§€ ê°’

    markdown_all = ""  # ì „ì²´ ê³µê³ 
    markdown_newbie = ""  # ì‹ ì… ê³µê³ 
    markdown_experienced = ""  # ê²½ë ¥ ê³µê³ 

    while True:
        PARAMS["page"] = page  # í˜„ì¬ í˜ì´ì§€ ì„¤ì •
        response = requests.get(API_URL, params=PARAMS, headers=JP_HEADERS)

        if response.status_code != 200:
            print(f"âŒ ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
            break

        data = response.json()
        
        job_list = data.get("data", {}).get("items", [])  # ì‹¤ì œ ì±„ìš© ê³µê³  ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        if not job_list:
            print("âœ… ë” ì´ìƒ ë°ì´í„° ì—†ìŒ â†’ í¬ë¡¤ë§ ì¢…ë£Œ")
            break  # ë” ì´ìƒ ë°ì´í„° ì—†ìœ¼ë©´ ì¢…ë£Œ

        all_jobs.extend(job_list)  # ê°€ì ¸ì˜¨ ë°ì´í„° ì¶”ê°€

        print(f"âœ… Page {page} - {len(job_list)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")

        for job in job_list:
            # ê³µê³  ì œëª©
            title = job.get("title", "ì œëª© ì—†ìŒ")

            # ì›í‹°ë“œ URL (id ê¸°ë°˜ ìƒì„±)
            job_id = job.get("id")
            job_url = f"https://www.jobplanet.co.kr/job/{job_id}" if job_id else "URL ì—†ìŒ"

            # íšŒì‚¬ëª…
            company_name = job.get("company", {}).get("name", "íšŒì‚¬ëª… ì—†ìŒ")

            # ê·¼ë¬´ ì§€ì—­
            location = job.get("company", {}).get("city_name", "ì§€ì—­ ì •ë³´ ì—†ìŒ")

            # ê²½ë ¥ ì •ë³´
            # 2 = ê²½ë ¥
            # 4 = ë¬´ê´€
            # 1 = ì‹ ì…
            is_newbie = job.get("annual", {}).get("type")[0]
            annual_from = job.get("annual", {}).get("years", 0)  # ìµœì†Œ ê²½ë ¥
            annual_to = job.get("annual", {}).get("maximum_years", 100)  # ìµœëŒ€ ê²½ë ¥

            if is_newbie == 1:
                career_info = "ì‹ ì…"
            elif is_newbie == 4:
                career_info = "ê²½ë ¥ë¬´ê´€"
            elif annual_from is not None and annual_to is not None:
                career_info = f"{annual_from}~{annual_to}ë…„ ê²½ë ¥"
            else:
                career_info = "ê²½ë ¥ ì •ë³´ ì—†ìŒ"

            deadline = job.get("deadline_message")

            # ë§ˆí¬ë‹¤ìš´ í¬ë§·ìœ¼ë¡œ ì €ì¥
            markdown_entry = f"\nğŸ”¹ Job: {title} ({company_name})\n"
            markdown_entry += f"ğŸ”— URL: {job_url}\n\n"
            markdown_entry += f"ğŸ“Œ **ìƒì„¸ ì •ë³´**: ['{career_info}', 'í•™ë ¥ë¬´ê´€', 'ì •ê·œì§', '{location}', '{deadline}']\n\n"
            markdown_entry += "---\n"

            # ì „ì²´ ë§ˆí¬ë‹¤ìš´
            markdown_all += markdown_entry

            # ì‹ ì… & ê²½ë ¥ êµ¬ë¶„ ì €ì¥
            if is_newbie == 1:
                markdown_newbie += markdown_entry  # ì‹ ì…, ê²½ë ¥ ë¬´ê´€ ì±„ìš© ê³µê³  ì €ì¥
            else:
                markdown_experienced += markdown_entry  # ê²½ë ¥ ì±„ìš© ê³µê³  ì €ì¥

        # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
        page += 1

        # ìš”ì²­ ì‚¬ì´ ë”œë ˆì´ ì¶”ê°€ (ì„œë²„ ì°¨ë‹¨ ë°©ì§€)
        time.sleep(1.5)


    # âœ… ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥
    job_list_folder = "job_list"
    os.makedirs(job_list_folder, exist_ok=True)  # í´ë” ì—†ìœ¼ë©´ ìë™ ìƒì„±

    with open(job_list_folder + "/all_job_list.md", "a", encoding="utf-8") as f:
        f.write(markdown_all)

    with open(job_list_folder + "/newbie_job_list.md", "a", encoding="utf-8") as f:
        f.write(markdown_newbie)

    with open(job_list_folder + "/1_to_3_experience_required_job_list.md", "a", encoding="utf-8") as f:
        f.write(markdown_experienced)

    print(f"âœ… ì´ {len(all_jobs)}ê°œì˜ ì±„ìš© ê³µê³  ì €ì¥ ì™„ë£Œ! (all_job_list.md, newbie_job_list.md, experienced_job_list.md)")
