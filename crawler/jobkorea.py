import requests, bs4


def job_korea_crawler(c_type, jk_headers):
    """
    c_type:
        1 = ì‹ ì…
        2 = ê²½ë ¥
        4 = ê²½ë ¥ë¬´ê´€
    """
    if c_type == 1:
        print("ğŸš€ì¡ì½”ë¦¬ì•„ ì‹ ì… ì±„ìš© ê³µê³  í¬ë¡¤ë§ ì‹œì‘")
    elif c_type == 1:
        print("ğŸš€ì¡ì½”ë¦¬ì•„ ê²½ë ¥ ì±„ìš© ê³µê³  í¬ë¡¤ë§ ì‹œì‘")
    else:
        print("ğŸš€ì¡ì½”ë¦¬ì•„ ê²½ë ¥ ë¬´ê´€ ì±„ìš© ê³µê³  í¬ë¡¤ë§ ì‹œì‘")
    JK_HEADERS = jk_headers
    page_no = 1
    markdown_content = "\n"  # ë§ˆí¬ë‹¤ìš´ ì €ì¥ìš© ë¬¸ìì—´

    while True:
        if c_type == 2:
            BASE_URL = rf"https://www.jobkorea.co.kr/Search/?stext=%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4&FeatureCode=WRK&duty=1000236&careerType={c_type}&careerMin=1&careerMax=3&tabType=recruit&Page_No={page_no}"
        else:
            BASE_URL = rf"https://www.jobkorea.co.kr/Search/?stext=%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4&FeatureCode=WRK&duty=1000236&careerType={c_type}&tabType=recruit&Page_No={page_no}"
        
        session = requests.Session()
        response = session.get(BASE_URL, headers=JK_HEADERS)

        # ì‘ë‹µ ìƒíƒœ í™•ì¸
        if response.status_code != 200:
            print(f"âŒ ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
            exit()

        response.encoding = "utf-8"
        html_content = response.text

        # BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±
        soup = bs4.BeautifulSoup(html_content, "html.parser")

        # í˜ì´ì§€ ë„˜ê¸°ê¸° ì¢…ë£Œ
        no_result = soup.select_one("p.list-empty-result")
        if no_result:
            print("âœ… ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ â†’ í¬ë¡¤ë§ ì¢…ë£Œ")
            break

        # XPathì— í•´ë‹¹í•˜ëŠ” ìœ„ì¹˜ ì°¾ê¸° (CSS Selector ì‚¬ìš©)
        target_section = soup.select_one("main div article article section:nth-of-type(1) article:nth-of-type(2)")

        if target_section:
            # 1ë²ˆì§¸ë¶€í„° 15ë²ˆì§¸ articleë§Œ ê°€ì ¸ì˜¤ê¸°
            job_articles = target_section.find_all("article")

            # ê²°ê³¼ ì¶œë ¥
            for idx, job in enumerate(job_articles, start=1):
                # ê³µê³  ì œëª© & ë§í¬ ì°¾ê¸°
                title_tag = job.select_one("div:nth-of-type(2) div a.information-title-link")
                title = title_tag.text.strip() if title_tag else "ì œëª© ì—†ìŒ"
                url = "https://www.jobkorea.co.kr" + title_tag["href"] if title_tag else "URL ì—†ìŒ"

                # /html/body/main/div/article/article/section[1]/article[2]/article[1]/div[2]/ul
                # ì¶”ê°€ ì •ë³´ í¬ë¡¤ë§ (ì‹ ì…/ê²½ë ¥, í•™ë ¥, ê·¼ë¬´ í˜•íƒœ, ì§€ì—­, ë§ˆê°ì¼)
                detail_list = job.select("ul.chip-information-group li.chip-information-item")
                details_text = [detail.text.strip() for detail in detail_list]

                # ë°ì´í„° ì¶œë ¥
                markdown_content += f"ğŸ”¹ Job: {title}\n"
                markdown_content += f"ğŸ”— URL: {url}\n\n"
                markdown_content += f"ğŸ“Œ **ìƒì„¸ ì •ë³´**: {details_text}\n\n"
                markdown_content += "---\n\n"

        else:
            print("âŒ í•´ë‹¹ ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        
        page_no += 1

    # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥
    job_list_folder = "job_list"
    if c_type == 1 or c_type == 4:
        file_name = job_list_folder + "/newbie_job_list.md"
    else:
        file_name = job_list_folder + "/1_to_3_experience_required_job_list.md"

    with open(file_name, "a", encoding="utf-8") as f:
        f.write(markdown_content)
    
    all_file_name = job_list_folder + "/all_job_list.md"
    with open(all_file_name, "a", encoding="utf-8") as f:
        f.write(markdown_content)
    
    print("âœ… í¬ë¡¤ë§ ì™„ë£Œ â†’ ë§ˆí¬ë‹¤ìš´ ì €ì¥ ì™„ë£Œ")
